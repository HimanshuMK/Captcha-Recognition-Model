{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15HHJxgcjCLS2zlj52MS2ztRBo7NAXfjl",
      "authorship_tag": "ABX9TyNMiWVDqJ7kah7QyHe1d5Qq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimanshuMK/Captcha-Recognition-Model/blob/main/My_Captcha_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "p_xlVQaNjBaL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQC7jhcH3pFl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2 #OpenCV(Open Source computer vision lib), containg CV algos\n",
        "import string\n",
        "import matplotlib.pyplot as plt #for graphs\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing data"
      ],
      "metadata": {
        "id": "igRzFK7VjZCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/OCR_model/samples'\n",
        "labels = []\n",
        "images = []"
      ],
      "metadata": {
        "id": "Rb54eDVm4JIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(data_dir):\n",
        "    # read image\n",
        "    img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
        "    images.append(img)\n",
        "\n",
        "    # extract labels from filename\n",
        "    label = filename.split('.')[0]\n",
        "    labels.append(label)"
      ],
      "metadata": {
        "id": "Bt8rYIyo4LBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(images).shape)\n",
        "print(np.array(labels).shape)"
      ],
      "metadata": {
        "id": "psHn_STK4M-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6731f278-69de-4728-857d-1e73c0b8c4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1070, 50, 200)\n",
            "(1070,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding"
      ],
      "metadata": {
        "id": "7vH4hVqlnmTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "characters= string.ascii_lowercase + string.digits # All symbols captcha can contain\n",
        "nchar = len(characters) #total number of char possible"
      ],
      "metadata": {
        "id": "GD0RoP7h4j4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding and Decoding Functions"
      ],
      "metadata": {
        "id": "QKrX03KXnu-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# character to number conversion\n",
        "char_to_num = {}\n",
        "for idx, char in enumerate(characters):\n",
        "    char_to_num[char] = idx\n",
        "\n",
        "# number to character conversion\n",
        "num_to_char = {}\n",
        "for char, idx in char_to_num.items():\n",
        "    num_to_char[idx] = char"
      ],
      "metadata": {
        "id": "8uq1NRDK44kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(images)\n",
        "print(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTVODlWu46xf",
        "outputId": "22fd595e-4855-4ef7-900f-97308c6ad787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing\n"
      ],
      "metadata": {
        "id": "C5Jf4yU75O2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# size of image is 50 rows x 200 cols\n",
        "# resize images\n",
        "resized_images = [cv2.resize(img, (200, 50)) for img in images]"
      ],
      "metadata": {
        "id": "33c3PBWo48al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing pixel values\n",
        "normalized_images = [img / 255.0 for img in resized_images]"
      ],
      "metadata": {
        "id": "WgmimO-K5Swm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max(len(label) for label in labels)\n",
        "num_classes = len(characters)\n",
        "print(max_length)\n",
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9gh2xsu5x-n",
        "outputId": "2d606d22-8bca-4ef2-fe09-8a58910a5a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding"
      ],
      "metadata": {
        "id": "Uhwho-jzoV0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_label(label):\n",
        "    encoded = np.zeros((max_length, num_classes), dtype=np.float32)\n",
        "    for i, char in enumerate(label):\n",
        "        encoded[i, char_to_num[char]] = 1.0\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "jwOEIcM35ydE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_labels = np.array([encode_label(label) for label in labels])"
      ],
      "metadata": {
        "id": "Jv6ZnQg051RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(normalized_images)  # Add channel dimension for grayscale\n",
        "y = np.array(encoded_labels)"
      ],
      "metadata": {
        "id": "G77T9iQN53W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(normalized_images))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SGe6AnQ56aD",
        "outputId": "5af1ec46-b033-45de-ab10-86b0d4eae9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1070\n",
            "(1070, 50, 200)\n",
            "(1070, 5, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split\n"
      ],
      "metadata": {
        "id": "AhBHJ-sX6flS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NWuc7UVO6ClK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Model"
      ],
      "metadata": {
        "id": "5E28rx2Z60j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import numpy as np\n",
        "\n",
        "# Define the improved model creation function\n",
        "def create_improved_model(imgshape, nchar, captcha_length):\n",
        "    img = layers.Input(shape=imgshape)  # Input image shape: (50, 200, 1)\n",
        "\n",
        "    # First convolutional block\n",
        "    conv1 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(img)\n",
        "    conv1 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(conv1)\n",
        "    mp1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)  # 25*100\n",
        "\n",
        "    # Second convolutional block\n",
        "    conv2 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(mp1)\n",
        "    conv2 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(conv2)\n",
        "    mp2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)  # 13*50\n",
        "\n",
        "    # Third convolutional block\n",
        "    conv3 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(mp2)\n",
        "    conv3 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(conv3)\n",
        "    bn = layers.BatchNormalization()(conv3)\n",
        "    mp3 = layers.MaxPooling2D(pool_size=(2, 2))(bn)  # 7*25\n",
        "\n",
        "    # Flatten the output\n",
        "    flat = layers.Flatten()(mp3)\n",
        "\n",
        "    # Fully connected layer\n",
        "    dens1 = layers.Dense(256, activation='relu')(flat)\n",
        "    drop1 = layers.Dropout(0.5)(dens1)\n",
        "    dens2 = layers.Dense(256, activation='relu')(drop1)\n",
        "    drop2 = layers.Dropout(0.5)(dens2)\n",
        "\n",
        "    # Output layer\n",
        "    res = layers.Dense(captcha_length * nchar, activation='softmax')(drop2)\n",
        "\n",
        "    # Reshape the output to (captcha_length, nchar)\n",
        "    reshaped = layers.Reshape((captcha_length, nchar))(res)\n",
        "\n",
        "    # Compile the model\n",
        "    model = Model(img, reshaped)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Assuming imgshape is (50, 200, 1), nchar is 36, and captcha_length is 5\n",
        "imgshape = (50, 200, 1)\n",
        "nchar = 36\n",
        "captcha_length = 5\n",
        "\n",
        "# Create the improved model\n",
        "model = create_improved_model(imgshape, nchar, captcha_length)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Assuming you have your data ready as X_train and y_train\n",
        "# X_train shape: (1070, 50, 200, 1)\n",
        "# y_train shape: (1070, 5, 36)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Create dummy data for demonstration (replace this with your actual data)\n",
        "# X_train = np.random.random((1070, 50, 200, 1))\n",
        "# y_train = np.random.random((1070, 5, 36))\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=80, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6dKpDsV6i_A",
        "outputId": "9d212515-2437-4f4a-ea94-e36af5ffa57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 50, 200, 1)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 50, 200, 32)       320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 50, 200, 32)       9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 25, 100, 32)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 25, 100, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 25, 100, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 12, 50, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 12, 50, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 50, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 12, 50, 128)       512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 6, 25, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 19200)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               4915456   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 180)               46260     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 5, 36)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5314452 (20.27 MB)\n",
            "Trainable params: 5314196 (20.27 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "22/22 [==============================] - 59s 3s/step - loss: 3.4899 - accuracy: 0.0611 - val_loss: 3.4426 - val_accuracy: 0.0988\n",
            "Epoch 2/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 3.1778 - accuracy: 0.0751 - val_loss: 3.3352 - val_accuracy: 0.0988\n",
            "Epoch 3/80\n",
            "22/22 [==============================] - 55s 3s/step - loss: 3.0822 - accuracy: 0.0766 - val_loss: 3.2736 - val_accuracy: 0.0988\n",
            "Epoch 4/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 3.0398 - accuracy: 0.0816 - val_loss: 3.3660 - val_accuracy: 0.0988\n",
            "Epoch 5/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 3.0100 - accuracy: 0.0901 - val_loss: 3.4115 - val_accuracy: 0.0919\n",
            "Epoch 6/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 2.9400 - accuracy: 0.1058 - val_loss: 3.3577 - val_accuracy: 0.0895\n",
            "Epoch 7/80\n",
            "22/22 [==============================] - 50s 2s/step - loss: 2.8947 - accuracy: 0.1175 - val_loss: 3.3499 - val_accuracy: 0.1163\n",
            "Epoch 8/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 2.8011 - accuracy: 0.1509 - val_loss: 3.2924 - val_accuracy: 0.1244\n",
            "Epoch 9/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 2.7202 - accuracy: 0.1646 - val_loss: 3.1242 - val_accuracy: 0.0698\n",
            "Epoch 10/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 2.6292 - accuracy: 0.1977 - val_loss: 3.1659 - val_accuracy: 0.1233\n",
            "Epoch 11/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 2.5675 - accuracy: 0.2164 - val_loss: 2.9938 - val_accuracy: 0.1174\n",
            "Epoch 12/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 2.4815 - accuracy: 0.2491 - val_loss: 2.9754 - val_accuracy: 0.0977\n",
            "Epoch 13/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 2.4219 - accuracy: 0.2442 - val_loss: 2.9683 - val_accuracy: 0.1872\n",
            "Epoch 14/80\n",
            "22/22 [==============================] - 50s 2s/step - loss: 2.3221 - accuracy: 0.2936 - val_loss: 2.8371 - val_accuracy: 0.2058\n",
            "Epoch 15/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 2.3051 - accuracy: 0.2906 - val_loss: 2.8700 - val_accuracy: 0.2093\n",
            "Epoch 16/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 2.2467 - accuracy: 0.2997 - val_loss: 2.7496 - val_accuracy: 0.2116\n",
            "Epoch 17/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 2.1807 - accuracy: 0.3213 - val_loss: 2.7601 - val_accuracy: 0.2163\n",
            "Epoch 18/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 2.1230 - accuracy: 0.3389 - val_loss: 2.6360 - val_accuracy: 0.2640\n",
            "Epoch 19/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 2.0711 - accuracy: 0.3599 - val_loss: 2.6151 - val_accuracy: 0.4105\n",
            "Epoch 20/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 2.0201 - accuracy: 0.3684 - val_loss: 2.5453 - val_accuracy: 0.2791\n",
            "Epoch 21/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 1.9344 - accuracy: 0.3918 - val_loss: 2.5700 - val_accuracy: 0.1907\n",
            "Epoch 22/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 1.8390 - accuracy: 0.4333 - val_loss: 2.3264 - val_accuracy: 0.4128\n",
            "Epoch 23/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 1.8356 - accuracy: 0.4175 - val_loss: 2.3228 - val_accuracy: 0.4151\n",
            "Epoch 24/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 1.7802 - accuracy: 0.4398 - val_loss: 2.1379 - val_accuracy: 0.4488\n",
            "Epoch 25/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 1.7008 - accuracy: 0.4728 - val_loss: 2.2434 - val_accuracy: 0.3802\n",
            "Epoch 26/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 1.6678 - accuracy: 0.4687 - val_loss: 2.0313 - val_accuracy: 0.4779\n",
            "Epoch 27/80\n",
            "22/22 [==============================] - 55s 2s/step - loss: 1.5743 - accuracy: 0.5038 - val_loss: 1.9874 - val_accuracy: 0.4233\n",
            "Epoch 28/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 1.5365 - accuracy: 0.5135 - val_loss: 1.7581 - val_accuracy: 0.5605\n",
            "Epoch 29/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 1.4527 - accuracy: 0.5363 - val_loss: 1.7705 - val_accuracy: 0.5767\n",
            "Epoch 30/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 1.4298 - accuracy: 0.5444 - val_loss: 1.6829 - val_accuracy: 0.5372\n",
            "Epoch 31/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 1.3805 - accuracy: 0.5556 - val_loss: 1.6013 - val_accuracy: 0.5988\n",
            "Epoch 32/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 1.3271 - accuracy: 0.5655 - val_loss: 1.4895 - val_accuracy: 0.5756\n",
            "Epoch 33/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 1.2948 - accuracy: 0.5880 - val_loss: 1.4033 - val_accuracy: 0.5988\n",
            "Epoch 34/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 1.2656 - accuracy: 0.5988 - val_loss: 1.4199 - val_accuracy: 0.6291\n",
            "Epoch 35/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 1.2480 - accuracy: 0.6006 - val_loss: 1.3525 - val_accuracy: 0.6209\n",
            "Epoch 36/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 1.1982 - accuracy: 0.6070 - val_loss: 1.3070 - val_accuracy: 0.6291\n",
            "Epoch 37/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 1.1525 - accuracy: 0.6190 - val_loss: 1.3503 - val_accuracy: 0.6174\n",
            "Epoch 38/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 1.1208 - accuracy: 0.6415 - val_loss: 1.3227 - val_accuracy: 0.5988\n",
            "Epoch 39/80\n",
            "22/22 [==============================] - 54s 2s/step - loss: 1.0967 - accuracy: 0.6404 - val_loss: 1.2651 - val_accuracy: 0.6267\n",
            "Epoch 40/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 1.0480 - accuracy: 0.6538 - val_loss: 1.2252 - val_accuracy: 0.6314\n",
            "Epoch 41/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 1.0354 - accuracy: 0.6596 - val_loss: 1.2400 - val_accuracy: 0.6430\n",
            "Epoch 42/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 1.0190 - accuracy: 0.6629 - val_loss: 1.1796 - val_accuracy: 0.6477\n",
            "Epoch 43/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 1.0041 - accuracy: 0.6737 - val_loss: 1.2389 - val_accuracy: 0.6605\n",
            "Epoch 44/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.9810 - accuracy: 0.6804 - val_loss: 1.1189 - val_accuracy: 0.6581\n",
            "Epoch 45/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.9922 - accuracy: 0.6675 - val_loss: 1.2269 - val_accuracy: 0.6802\n",
            "Epoch 46/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.9007 - accuracy: 0.7099 - val_loss: 1.0713 - val_accuracy: 0.6849\n",
            "Epoch 47/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.8536 - accuracy: 0.7173 - val_loss: 1.1638 - val_accuracy: 0.6663\n",
            "Epoch 48/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.9147 - accuracy: 0.6982 - val_loss: 1.0601 - val_accuracy: 0.6965\n",
            "Epoch 49/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.8703 - accuracy: 0.7096 - val_loss: 1.2370 - val_accuracy: 0.6244\n",
            "Epoch 50/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.8512 - accuracy: 0.7181 - val_loss: 1.0431 - val_accuracy: 0.6791\n",
            "Epoch 51/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.8199 - accuracy: 0.7263 - val_loss: 1.0495 - val_accuracy: 0.6802\n",
            "Epoch 52/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.7928 - accuracy: 0.7339 - val_loss: 0.9771 - val_accuracy: 0.7047\n",
            "Epoch 53/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.7659 - accuracy: 0.7427 - val_loss: 0.9871 - val_accuracy: 0.6965\n",
            "Epoch 54/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.7463 - accuracy: 0.7520 - val_loss: 1.0437 - val_accuracy: 0.6802\n",
            "Epoch 55/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.7211 - accuracy: 0.7635 - val_loss: 1.0034 - val_accuracy: 0.6744\n",
            "Epoch 56/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.8149 - accuracy: 0.7357 - val_loss: 1.1393 - val_accuracy: 0.6709\n",
            "Epoch 57/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.7679 - accuracy: 0.7558 - val_loss: 0.9965 - val_accuracy: 0.6953\n",
            "Epoch 58/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.7338 - accuracy: 0.7655 - val_loss: 1.0262 - val_accuracy: 0.7012\n",
            "Epoch 59/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.7147 - accuracy: 0.7635 - val_loss: 1.0117 - val_accuracy: 0.6919\n",
            "Epoch 60/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.6991 - accuracy: 0.7702 - val_loss: 0.9091 - val_accuracy: 0.7326\n",
            "Epoch 61/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.7122 - accuracy: 0.7661 - val_loss: 0.9829 - val_accuracy: 0.7093\n",
            "Epoch 62/80\n",
            "22/22 [==============================] - 54s 3s/step - loss: 0.7245 - accuracy: 0.7611 - val_loss: 0.9394 - val_accuracy: 0.7302\n",
            "Epoch 63/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.6310 - accuracy: 0.7953 - val_loss: 0.9184 - val_accuracy: 0.7233\n",
            "Epoch 64/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.6834 - accuracy: 0.7632 - val_loss: 0.9785 - val_accuracy: 0.7163\n",
            "Epoch 65/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.6308 - accuracy: 0.7904 - val_loss: 0.9018 - val_accuracy: 0.7326\n",
            "Epoch 66/80\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.6593 - accuracy: 0.7860 - val_loss: 0.9556 - val_accuracy: 0.7233\n",
            "Epoch 67/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.6451 - accuracy: 0.7851 - val_loss: 0.9286 - val_accuracy: 0.7233\n",
            "Epoch 68/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.6545 - accuracy: 0.7833 - val_loss: 0.9269 - val_accuracy: 0.7198\n",
            "Epoch 69/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.6333 - accuracy: 0.7822 - val_loss: 0.8924 - val_accuracy: 0.7314\n",
            "Epoch 70/80\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.6020 - accuracy: 0.8056 - val_loss: 0.8710 - val_accuracy: 0.7372\n",
            "Epoch 71/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.5756 - accuracy: 0.8070 - val_loss: 0.8235 - val_accuracy: 0.7302\n",
            "Epoch 72/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.5979 - accuracy: 0.8023 - val_loss: 0.8672 - val_accuracy: 0.7605\n",
            "Epoch 73/80\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.5897 - accuracy: 0.7965 - val_loss: 0.8819 - val_accuracy: 0.7314\n",
            "Epoch 74/80\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.5729 - accuracy: 0.8096 - val_loss: 0.8646 - val_accuracy: 0.7430\n",
            "Epoch 75/80\n",
            "22/22 [==============================] - 59s 3s/step - loss: 0.5732 - accuracy: 0.8135 - val_loss: 0.9021 - val_accuracy: 0.7140\n",
            "Epoch 76/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.5630 - accuracy: 0.8123 - val_loss: 0.8685 - val_accuracy: 0.7465\n",
            "Epoch 77/80\n",
            "22/22 [==============================] - 52s 2s/step - loss: 0.5780 - accuracy: 0.8140 - val_loss: 0.8585 - val_accuracy: 0.7453\n",
            "Epoch 78/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.5719 - accuracy: 0.8038 - val_loss: 0.8500 - val_accuracy: 0.7465\n",
            "Epoch 79/80\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.5337 - accuracy: 0.8243 - val_loss: 0.9038 - val_accuracy: 0.7337\n",
            "Epoch 80/80\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.5706 - accuracy: 0.8137 - val_loss: 0.8486 - val_accuracy: 0.7349\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x785ab97babc0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
        "print(f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "test_loss, test_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTcemvxY7DOv",
        "outputId": "956faced-d7f4-410a-ebba-cc7217cac117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 18s 652ms/step - loss: 0.2019 - accuracy: 0.9456\n",
            "Training Loss: 0.2019, Training Accuracy: 0.9456\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.8178 - accuracy: 0.7374\n",
            "Testing Loss: 0.8178, Testing Accuracy: 0.7374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Compute additional metrics\n",
        "# Convert one-hot encoded labels back to integers\n",
        "y_test_int = np.argmax(y_val, axis=-1).reshape(-1, captcha_length)\n",
        "y_pred_int = np.argmax(y_pred, axis=-1).reshape(-1, captcha_length)\n",
        "\n",
        "# Compute accuracy for each position in the captcha\n",
        "accuracy_per_position = np.mean([accuracy_score(y_test_int[:, i], y_pred_int[:, i]) for i in range(captcha_length)])\n",
        "print(f'Accuracy per position: {accuracy_per_position:.4f}')\n",
        "\n",
        "# Compute overall accuracy, precision, recall, and F1 score\n",
        "overall_accuracy = accuracy_score(y_test_int.flatten(), y_pred_int.flatten())\n",
        "precision = precision_score(y_test_int.flatten(), y_pred_int.flatten(), average='macro')\n",
        "recall = recall_score(y_test_int.flatten(), y_pred_int.flatten(), average='macro')\n",
        "f1 = f1_score(y_test_int.flatten(), y_pred_int.flatten(), average='macro')\n",
        "\n",
        "print(f'Overall Accuracy: {overall_accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnZq1wuh7bxT",
        "outputId": "f44df67b-af52-4b1b-e584-dc12ee673baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 430ms/step\n",
            "Accuracy per position: 0.7374\n",
            "Overall Accuracy: 0.7374\n",
            "Precision: 0.7475\n",
            "Recall: 0.7382\n",
            "F1 Score: 0.7392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the save path\n",
        "save_path = '/content/drive/MyDrive/OCR_model/my_captcha_model_v1.keras'\n",
        "# Save the model\n",
        "model.save(save_path)\n"
      ],
      "metadata": {
        "id": "bTfgfW8OJ6Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To increase its accuracy we will try to run it for more epochs"
      ],
      "metadata": {
        "id": "ppFOuj85pqKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgshape = (50, 200, 1)\n",
        "nchar = 36\n",
        "captcha_length = 5"
      ],
      "metadata": {
        "id": "9N_UeFzRv8o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/drive/MyDrive/OCR_model/my_captcha_model_v1.keras')\n"
      ],
      "metadata": {
        "id": "s_CIwICEIhP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue training the loaded model for additional epochs\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YocrUwOzp63B",
        "outputId": "add9b309-8191-49ff-e7a8-2c5c3ab80fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 55s 2s/step - loss: 0.5429 - accuracy: 0.8240 - val_loss: 0.8398 - val_accuracy: 0.7453\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 52s 2s/step - loss: 0.5624 - accuracy: 0.8219 - val_loss: 0.8186 - val_accuracy: 0.7581\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.5213 - accuracy: 0.8287 - val_loss: 0.9503 - val_accuracy: 0.7128\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.5362 - accuracy: 0.8231 - val_loss: 0.9815 - val_accuracy: 0.7267\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.5091 - accuracy: 0.8363 - val_loss: 0.8571 - val_accuracy: 0.7453\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.5637 - accuracy: 0.8137 - val_loss: 0.8395 - val_accuracy: 0.7500\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.5127 - accuracy: 0.8313 - val_loss: 0.8395 - val_accuracy: 0.7523\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4970 - accuracy: 0.8345 - val_loss: 0.8337 - val_accuracy: 0.7326\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.5103 - accuracy: 0.8333 - val_loss: 0.8594 - val_accuracy: 0.7395\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.5084 - accuracy: 0.8284 - val_loss: 0.8955 - val_accuracy: 0.7372\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.4822 - accuracy: 0.8342 - val_loss: 0.8759 - val_accuracy: 0.7488\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4988 - accuracy: 0.8368 - val_loss: 0.8183 - val_accuracy: 0.7523\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.5122 - accuracy: 0.8295 - val_loss: 0.9479 - val_accuracy: 0.7302\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.4720 - accuracy: 0.8433 - val_loss: 0.8564 - val_accuracy: 0.7372\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.4647 - accuracy: 0.8398 - val_loss: 0.8119 - val_accuracy: 0.7395\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.4690 - accuracy: 0.8406 - val_loss: 0.8783 - val_accuracy: 0.7314\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4965 - accuracy: 0.8266 - val_loss: 0.8836 - val_accuracy: 0.7395\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4607 - accuracy: 0.8485 - val_loss: 0.8333 - val_accuracy: 0.7616\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.4592 - accuracy: 0.8477 - val_loss: 0.8411 - val_accuracy: 0.7547\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.4450 - accuracy: 0.8585 - val_loss: 0.7468 - val_accuracy: 0.7756\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.4475 - accuracy: 0.8494 - val_loss: 0.8065 - val_accuracy: 0.7547\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4392 - accuracy: 0.8576 - val_loss: 0.8107 - val_accuracy: 0.7547\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.4310 - accuracy: 0.8620 - val_loss: 0.7967 - val_accuracy: 0.7651\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.4221 - accuracy: 0.8544 - val_loss: 0.7951 - val_accuracy: 0.7593\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.4488 - accuracy: 0.8500 - val_loss: 0.8133 - val_accuracy: 0.7547\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.4591 - accuracy: 0.8477 - val_loss: 0.8170 - val_accuracy: 0.7523\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4258 - accuracy: 0.8564 - val_loss: 0.7888 - val_accuracy: 0.7733\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4089 - accuracy: 0.8670 - val_loss: 0.7827 - val_accuracy: 0.7651\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4445 - accuracy: 0.8523 - val_loss: 0.8707 - val_accuracy: 0.7419\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.4310 - accuracy: 0.8596 - val_loss: 0.8300 - val_accuracy: 0.7407\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7968576a11e0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
        "print(f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "test_loss, test_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_93QUUC9wsZh",
        "outputId": "d038da22-6b91-42ec-9e85-add73dd5c671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 15s 552ms/step - loss: 0.1778 - accuracy: 0.9477\n",
            "Training Loss: 0.1778, Training Accuracy: 0.9477\n",
            "7/7 [==============================] - 3s 418ms/step - loss: 0.8046 - accuracy: 0.7692\n",
            "Testing Loss: 0.8046, Testing Accuracy: 0.7692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Compute additional metrics\n",
        "# Convert one-hot encoded labels back to integers\n",
        "y_test_int = np.argmax(y_val, axis=-1).reshape(-1, captcha_length)\n",
        "y_pred_int = np.argmax(y_pred, axis=-1).reshape(-1, captcha_length)\n",
        "\n",
        "# Compute accuracy for each position in the captcha\n",
        "accuracy_per_position = np.mean([accuracy_score(y_test_int[:, i], y_pred_int[:, i]) for i in range(captcha_length)])\n",
        "print(f'Accuracy per position: {accuracy_per_position:.4f}')\n",
        "\n",
        "# Compute overall accuracy, precision, recall, and F1 score\n",
        "overall_accuracy = accuracy_score(y_test_int.flatten(), y_pred_int.flatten())\n",
        "precision = precision_score(y_test_int.flatten(), y_pred_int.flatten(), average='macro')\n",
        "recall = recall_score(y_test_int.flatten(), y_pred_int.flatten(), average='macro')\n",
        "f1 = f1_score(y_test_int.flatten(), y_pred_int.flatten(), average='macro')\n",
        "\n",
        "print(f'Overall Accuracy: {overall_accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtqcAFi3qIEb",
        "outputId": "0b508ae4-6d37-4ae6-96c9-beb5d3933595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 419ms/step\n",
            "Accuracy per position: 0.7692\n",
            "Overall Accuracy: 0.7692\n",
            "Precision: 0.7737\n",
            "Recall: 0.7677\n",
            "F1 Score: 0.7674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is now greater than 75 %, so its quite acceptable"
      ],
      "metadata": {
        "id": "ASMOJo1fomKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the save path\n",
        "save_path = '/content/drive/MyDrive/OCR_model/my_captcha_model_v1_1.keras'\n",
        "# Save the model\n",
        "model.save(save_path)\n"
      ],
      "metadata": {
        "id": "1aO1VEOLvyoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to predict for particular image of Captcha"
      ],
      "metadata": {
        "id": "KdJy5P4oow9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = cv2.imread('/content/drive/MyDrive/OCR_model/samples/x37bf.png', cv2.IMREAD_GRAYSCALE)\n",
        "img1 = img1 / 255.0\n",
        "res1 = np.array(model.predict(img1[np.newaxis, :, :, np.newaxis]))\n",
        "result1 = np.reshape(res1, (5, 36)) #reshape the array\n",
        "k_ind = []\n",
        "probs = []\n",
        "for i in result1:\n",
        "    k_ind.append(np.argmax(i)) #adds the index of the char found in captcha\n",
        "\n",
        "capt = '' #string to store predicted captcha\n",
        "for k in k_ind:\n",
        "    capt += num_to_char[k] #finds the char corresponding to the index\n",
        "print(capt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZahX0qIw-M3",
        "outputId": "68120012-ca3c-4e4f-e838-9f153a2933bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 142ms/step\n",
            "x37bf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The End"
      ],
      "metadata": {
        "id": "QmAkUyxfo6SC"
      }
    }
  ]
}